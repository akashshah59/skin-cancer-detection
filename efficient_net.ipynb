{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nHOME_DIRECTORY = 'kaggle/input/isic-2024-challenge/'\ntrain_metadata = pd.read_csv('/kaggle/input/isic-2024-challenge/train-metadata.csv',low_memory = True)\ntest_metadata = pd.read_csv('/kaggle/input/isic-2024-challenge/test-metadata.csv',low_memory =True)\n\nfrom category_encoders.hashing import HashingEncoder\nfrom sklearn.pipeline import make_pipeline \nfrom sklearn.impute import KNNImputer\nfrom lightgbm import LGBMClassifier\n\n\nlgb_params = {\n    'objective': 'binary',\n    \"random_state\": 42,\n    \"n_estimators\": 500,\n    'learning_rate': 0.01,\n    'bagging_freq': 1,\n    'pos_bagging_fraction': 0.75,\n    'neg_bagging_fraction': 0.05,\n    'feature_fraction': 0.8,\n    'lambda_l1': 0.8,\n    'lambda_l2': 0.8,\n    \"verbosity\": -1,\n    # \"extra_trees\": True\n}\n\ntrain_only_features = ['lesion_id',\n                       'iddx_full',\n                       'iddx_1',\n                       'iddx_2',\n                       'iddx_3',\n                       'iddx_4',\n                       'iddx_5',\n                       'mel_mitotic_index',\n                       'mel_thick_mm',\n                       'tbp_lv_dnn_lesion_confidence']\n\ntrain_compressed = train_metadata.drop(train_only_features, axis = 1)\n\npip = make_pipeline(HashingEncoder(),\n                    KNNImputer(),\n                    LGBMClassifier(**lgb_params)) ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-12T23:51:04.557225Z","iopub.execute_input":"2024-07-12T23:51:04.558188Z","iopub.status.idle":"2024-07-12T23:51:04.563930Z","shell.execute_reply.started":"2024-07-12T23:51:04.558127Z","shell.execute_reply":"2024-07-12T23:51:04.562837Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%time\npip.fit(train_compressed.drop('target',\n                               axis = 1), train_compressed['target'])\n\n\nprob_encoder = pip.predict_proba(test_metadata)[:,1]","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:44:29.302662Z","iopub.execute_input":"2024-07-12T23:44:29.302966Z","iopub.status.idle":"2024-07-12T23:44:29.307017Z","shell.execute_reply.started":"2024-07-12T23:44:29.302941Z","shell.execute_reply":"2024-07-12T23:44:29.306081Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nwith open('metadata-model.pkl','wb') as f:\n    pickle.dump(pip,f)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:44:29.637852Z","iopub.execute_input":"2024-07-12T23:44:29.638499Z","iopub.status.idle":"2024-07-12T23:44:29.642046Z","shell.execute_reply.started":"2024-07-12T23:44:29.638462Z","shell.execute_reply":"2024-07-12T23:44:29.641151Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nimport torch\nimport torch.nn as nn\n\nmodel = models.efficientnet_b0(weights = None)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:44:30.590112Z","iopub.execute_input":"2024-07-12T23:44:30.590529Z","iopub.status.idle":"2024-07-12T23:44:35.571400Z","shell.execute_reply.started":"2024-07-12T23:44:30.590494Z","shell.execute_reply":"2024-07-12T23:44:35.570618Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sum([p.numel() for p in model.features.parameters()]) + sum([p.numel() for p in model.classifier.parameters()])\n  ","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:44:35.572977Z","iopub.execute_input":"2024-07-12T23:44:35.573362Z","iopub.status.idle":"2024-07-12T23:44:35.581917Z","shell.execute_reply.started":"2024-07-12T23:44:35.573336Z","shell.execute_reply":"2024-07-12T23:44:35.581085Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"5288548"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:44:35.583069Z","iopub.execute_input":"2024-07-12T23:44:35.583391Z","iopub.status.idle":"2024-07-12T23:44:35.599631Z","shell.execute_reply.started":"2024-07-12T23:44:35.583360Z","shell.execute_reply":"2024-07-12T23:44:35.598487Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=True)\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for p in model.features.parameters():\n    p.requires_grad = True\n\nmodel.classifier.add_module('flatten', nn.Flatten())\nmodel.classifier.add_module('fc', nn.Linear(1000,1))\nmodel.classifier.add_module('sigmoid',nn.Sigmoid())","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:50:58.969912Z","iopub.execute_input":"2024-07-12T23:50:58.970290Z","iopub.status.idle":"2024-07-12T23:50:59.016747Z","shell.execute_reply.started":"2024-07-12T23:50:58.970262Z","shell.execute_reply":"2024-07-12T23:50:59.015518Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m      2\u001b[0m     p\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39madd_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflatten\u001b[39m\u001b[38;5;124m'\u001b[39m, nn\u001b[38;5;241m.\u001b[39mFlatten())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'features'"],"ename":"AttributeError","evalue":"'DataParallel' object has no attribute 'features'","output_type":"error"}]},{"cell_type":"code","source":"# import pandas as pd \n\n# HOME_DIRECTORY = '/kaggle/input/isic-2024-challenge/'\n# df = pd.read_csv(HOME_DIRECTORY + 'train-metadata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:44:45.169189Z","iopub.execute_input":"2024-07-12T23:44:45.169625Z","iopub.status.idle":"2024-07-12T23:44:45.174131Z","shell.execute_reply.started":"2024-07-12T23:44:45.169593Z","shell.execute_reply":"2024-07-12T23:44:45.173223Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:44:50.060322Z","iopub.execute_input":"2024-07-12T23:44:50.060727Z","iopub.status.idle":"2024-07-12T23:44:50.094691Z","shell.execute_reply.started":"2024-07-12T23:44:50.060686Z","shell.execute_reply":"2024-07-12T23:44:50.093666Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Available devices:\")\nif torch.cuda.is_available():\n    for i in range(torch.cuda.device_count()):\n        print(f\"CUDA:{i} - {torch.cuda.get_device_name(i)}\")\n    model = nn.DataParallel(model).to(device)\nelse:\n    print(\"CPU\")\n\n# Get the current device\ncurrent_device = torch.cuda.current_device()\nprint(f\"\\nCurrent device: {current_device}\")\n\n# Get the default device\ndefault_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Default device: {default_device}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:44:51.039235Z","iopub.execute_input":"2024-07-12T23:44:51.040620Z","iopub.status.idle":"2024-07-12T23:44:51.231069Z","shell.execute_reply.started":"2024-07-12T23:44:51.040563Z","shell.execute_reply":"2024-07-12T23:44:51.230141Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Available devices:\nCUDA:0 - Tesla P100-PCIE-16GB\n\nCurrent device: 0\nDefault device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport os\nimport io\nimport h5py\nimport cv2\n\nclass SkinDataset(Dataset):\n    \"\"\"Predict melanoma cancer\"\"\"\n\n    def __init__(self, root_dir, transform=None, train_metadata = None, is_h5py = False, is_train= True):\n        \"\"\"\n        Arguments:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.root_dir = root_dir\n        self.train_metadata = train_metadata\n        self.is_h5py = is_h5py\n        self.is_train = is_train \n        \n        if self.is_h5py:\n            self.file = h5py.File(root_dir, 'r')\n        \n        self.transform = transform\n        \n\n    def __len__(self):\n        return len(self.train_metadata)\n\n    def __getitem__(self, idx):\n        \n        img_id = self.train_metadata.iloc[idx, 0]\n        \n        if not self.is_h5py:\n            img_name = os.path.join(self.root_dir,\n                                    img_id + '.jpg')\n            image = Image.open(img_name).convert('RGB')\n        else:\n            image_data = self.file[img_id][()]\n            image = Image.open(io.BytesIO(image_data)).convert('RGB')\n        \n\n        if self.transform:\n            image = self.hair_remove(image)\n            image = self.transform(image)\n        \n        if self.is_train:\n            targets = self.train_metadata.iloc[idx, 1]\n            targets = torch.Tensor([targets]).float()\n            return image,targets\n        else:\n            return image\n            \n    def hair_remove(self,image):\n        # Apply Black hat transformation to image. \n        grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        kernel = cv2.getStructuringElement(1,(17,17))\n        blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n        _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n        final_image = cv2.inpaint(image,threshold,1,cv2.INPAINT_TELEA)\n\n    return final_image\n    \n    def __del__(self):\n        if self.is_h5py:\n            self.file.close()\n    \n\nSAMPLE_IMAGE_DIRECTORY = '/kaggle/input/isic-2024-challenge/train-image/image/'\nHOME_DIRECTORY = '/kaggle/input/isic-2024-challenge/'\nSAMPLE_TRAIN_IMAGE_DIRECTORY = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\nSAMPLE_TEST_IMAGE_DIRECTORY = '/kaggle/input/isic-2024-challenge/test-image.hdf5'","metadata":{"execution":{"iopub.status.busy":"2024-07-17T22:19:38.710237Z","iopub.execute_input":"2024-07-17T22:19:38.710618Z","iopub.status.idle":"2024-07-17T22:19:45.822242Z","shell.execute_reply.started":"2024-07-17T22:19:38.710586Z","shell.execute_reply":"2024-07-17T22:19:45.821190Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n                        transforms.Resize(256),\n                        transforms.CenterCrop(224),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], # Standards used by other datasets\n                                             std=[0.229, 0.224, 0.225]) # Sta\n                    ])\n\ndf = pd.read_csv(HOME_DIRECTORY + 'train-metadata.csv', \n                             usecols = ['isic_id','target'])\n\ntest_metadata = pd.read_csv(HOME_DIRECTORY + 'test-metadata.csv', \n                             usecols = ['isic_id'])\n\ntrain_metadata, val_metadata = train_test_split(df)\n\ntrain_dataset = SkinDataset(SAMPLE_TRAIN_IMAGE_DIRECTORY, \n                             transform , \n                            train_metadata, \n                            is_h5py = True,\n                            is_train = True)\n\nval_dataset = SkinDataset( SAMPLE_TRAIN_IMAGE_DIRECTORY, \n                              transform , \n                              val_metadata, \n                              is_h5py = True,\n                              is_train = True)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:29:09.269375Z","iopub.execute_input":"2024-07-12T22:29:09.269994Z","iopub.status.idle":"2024-07-12T22:29:12.002201Z","shell.execute_reply.started":"2024-07-12T22:29:09.269963Z","shell.execute_reply":"2024-07-12T22:29:12.001155Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"test_dataset = SkinDataset( SAMPLE_TEST_IMAGE_DIRECTORY, \n                            transform , \n                            test_metadata,\n                            is_h5py = True,\n                            is_train = False)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:29:12.004021Z","iopub.execute_input":"2024-07-12T22:29:12.004359Z","iopub.status.idle":"2024-07-12T22:29:12.009495Z","shell.execute_reply.started":"2024-07-12T22:29:12.004333Z","shell.execute_reply":"2024-07-12T22:29:12.008533Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"def calc_sample_weights(df):\n    class_counts = df['target'].value_counts().to_dict()\n    class_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n\n    sample_weights = [class_weights[target] for target in df['target']]\n\n    class_weights\n    return sample_weights, class_weights","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:29:12.010636Z","iopub.execute_input":"2024-07-12T22:29:12.010895Z","iopub.status.idle":"2024-07-12T22:29:12.021015Z","shell.execute_reply.started":"2024-07-12T22:29:12.010873Z","shell.execute_reply":"2024-07-12T22:29:12.020171Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import  WeightedRandomSampler\n\nsample_weights,class_weights = calc_sample_weights(train_metadata)\nsampler = WeightedRandomSampler(\n                                weights=sample_weights, \n                                num_samples = len(sample_weights), \n                                replacement=True)\n\ntrain_loader = DataLoader(train_dataset,batch_size = 32 , sampler = sampler)\nval_loader = DataLoader(val_dataset,batch_size = 32 )\ntest_loader = DataLoader(test_dataset, batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:29:12.035608Z","iopub.execute_input":"2024-07-12T22:29:12.035872Z","iopub.status.idle":"2024-07-12T22:29:12.157486Z","shell.execute_reply.started":"2024-07-12T22:29:12.035850Z","shell.execute_reply":"2024-07-12T22:29:12.156236Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\ndef score(solution: np.array, submission: np.array, min_tpr: float=0.80) -> float:\n\n    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n    v_gt = abs(solution-1)\n    \n    # flip the submissions to their compliments\n    v_pred = -1.0 * submission\n\n    max_fpr = abs(1-min_tpr)\n\n    # using sklearn.metric functions: (1) roc_curve and (2) auc\n    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n    if max_fpr is None or max_fpr == 1:\n        return auc(fpr, tpr)\n    if max_fpr <= 0 or max_fpr > 1:\n        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n        \n    # Add a single point at max_fpr by linear interpolation\n    stop = np.searchsorted(fpr, max_fpr, \"right\")\n    x_interp = [fpr[stop - 1], fpr[stop]]\n    y_interp = [tpr[stop - 1], tpr[stop]]\n    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n    fpr = np.append(fpr[:stop], max_fpr)\n    partial_auc = auc(fpr, tpr)\n    \n    return partial_auc","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:29:13.295323Z","iopub.execute_input":"2024-07-12T22:29:13.295684Z","iopub.status.idle":"2024-07-12T22:29:13.304594Z","shell.execute_reply.started":"2024-07-12T22:29:13.295656Z","shell.execute_reply":"2024-07-12T22:29:13.303569Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/edomingo/isic-24-scd-basic-eda-pytorch-simple-cnn?scriptVersionId=187691769&cellId=30\n# https://www.kaggle.com/code/ayrgthonsoraca/skin-cancer-detection-cnn-img-csv","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:29:15.208799Z","iopub.execute_input":"2024-07-12T22:29:15.209162Z","iopub.status.idle":"2024-07-12T22:29:15.213388Z","shell.execute_reply.started":"2024-07-12T22:29:15.209134Z","shell.execute_reply":"2024-07-12T22:29:15.212368Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"from torch.optim import Adam,SGD\nfrom torch.nn import BCELoss,BCEWithLogitsLoss\nimport os\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\noptimizer = SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, momentum = 0.9)\ncriterion = BCELoss()\n\n\ndebug = False\n\n# Train the model\nmodel.train()\nfor epoch in range(1):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(tqdm(train_loader)):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs).flatten()\n        loss = criterion(outputs.unsqueeze(1), labels.float())\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        n = 1000\n        if i % n == n-1:    # print every 2000 mini-batches\n            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss/n:.4f}\")\n            running_loss = 0.0\n        \n        if debug:\n            if i > n: break\n            \n    correct = 0\n    total = 0\n    all_probs = []\n    all_labels = []\n    # since we're not training, we don't need to calculate the gradients for our outputs\n    with torch.no_grad():\n        for i, data in enumerate(tqdm(val_loader)):\n            images, labels = data[0].to(device), data[1].float().to(device)\n            # calculate outputs by running images through the network\n            probs = model(images).flatten()\n            all_probs.extend(probs.cpu().tolist())\n            all_labels.extend(labels.cpu().tolist())\n            # the class with the highest energy is what we choose as prediction\n            predicted = (probs >= 0.5).float()\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            if debug:\n                if i > 3: break\n\n    print(len(all_labels), len(all_probs))\n    print(all_labels[:5], all_probs[:5])\n                  \n    print(f\"Accuracy of the model: {100 * correct // total} %\")\n    print(f\"AUC of the model: {score(np.array(all_labels), np.array(all_probs), min_tpr=0.0)}\")\n    print(f\"pAUC-TPR(0.8) of the model: {score(np.array(all_labels), np.array(all_probs))}\")\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:30:10.206573Z","iopub.execute_input":"2024-07-12T22:30:10.207236Z","iopub.status.idle":"2024-07-12T22:32:04.823891Z","shell.execute_reply.started":"2024-07-12T22:30:10.207194Z","shell.execute_reply":"2024-07-12T22:32:04.822389Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stderr","text":"  1%|          | 100/9400 [00:28<41:58,  3.69it/s]","output_type":"stream"},{"name":"stdout","text":"[1,   100] loss: 0.6788\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 200/9400 [00:55<41:40,  3.68it/s]","output_type":"stream"},{"name":"stdout","text":"[1,   200] loss: 0.6367\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 300/9400 [01:22<40:16,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"[1,   300] loss: 0.5963\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 400/9400 [01:48<38:43,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"[1,   400] loss: 0.5804\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 420/9400 [01:54<40:47,  3.67it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[124], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"OUTPUT_PATH = '/kaggle/working/efficient_net.pt'\ntorch.save(model, OUTPUT_PATH)\n#### Saving entire model for simplicity. \n\nmodel = torch.load(OUTPUT_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T21:40:06.985947Z","iopub.execute_input":"2024-07-12T21:40:06.986855Z","iopub.status.idle":"2024-07-12T21:40:07.419064Z","shell.execute_reply.started":"2024-07-12T21:40:06.986818Z","shell.execute_reply":"2024-07-12T21:40:07.418040Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): EfficientNet(\n    (features): Sequential(\n      (0): Conv2dNormActivation(\n        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SiLU(inplace=True)\n      )\n      (1): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (2): Conv2dNormActivation(\n              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n        )\n      )\n      (2): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n        )\n      )\n      (3): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n        )\n      )\n      (4): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n        )\n      )\n      (5): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n        )\n      )\n      (6): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n        )\n      )\n      (7): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): Conv2dNormActivation(\n              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): Conv2dNormActivation(\n              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): Conv2dNormActivation(\n              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n        )\n      )\n      (8): Conv2dNormActivation(\n        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): SiLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=1)\n    (classifier): Sequential(\n      (0): Dropout(p=0.2, inplace=True)\n      (1): Linear(in_features=1280, out_features=1000, bias=True)\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n      (fc): Linear(in_features=1000, out_features=1, bias=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\n\npreds = []\nfor i,data in enumerate(test_loader):\n    preds.append(model(data).to('cpu').detach().numpy())\n\npreds = np.concatenate(preds)\nprobs = pip.predict_proba(test_metadata)[:,1]","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:24:04.852834Z","iopub.execute_input":"2024-07-12T22:24:04.853170Z","iopub.status.idle":"2024-07-12T22:24:04.888352Z","shell.execute_reply.started":"2024-07-12T22:24:04.853144Z","shell.execute_reply":"2024-07-12T22:24:04.887584Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"submission_metadata = pd.read_csv(HOME_DIRECTORY + 'test-metadata.csv', \n                             usecols = ['isic_id'])\nsubmission_metadata['target'] = np.max([probs, preds], axis = 0) # Pick max probability of cancer. \nsubmission_metadata.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:24:33.997744Z","iopub.execute_input":"2024-07-12T22:24:33.998475Z","iopub.status.idle":"2024-07-12T22:24:34.009235Z","shell.execute_reply.started":"2024-07-12T22:24:33.998440Z","shell.execute_reply":"2024-07-12T22:24:34.008472Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}